{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:15:30.667339Z",
     "iopub.status.busy": "2024-11-19T19:15:30.666640Z",
     "iopub.status.idle": "2024-11-19T19:15:33.401658Z",
     "shell.execute_reply": "2024-11-19T19:15:33.400859Z",
     "shell.execute_reply.started": "2024-11-19T19:15:30.667302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = pd.read_csv(\"doc_query_pairs.train.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:15:33.403423Z",
     "iopub.status.busy": "2024-11-19T19:15:33.403099Z",
     "iopub.status.idle": "2024-11-19T19:15:33.412753Z",
     "shell.execute_reply": "2024-11-19T19:15:33.411796Z",
     "shell.execute_reply.started": "2024-11-19T19:15:33.403363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.</th>\n",
       "      <th>)what was the immediate impact of the success of the manhattan project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The approach is based on a theory of justice t...</td>\n",
       "      <td>_________ justice is designed to repair the ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colorâurine can be a variety of colors, most...</td>\n",
       "      <td>what color is amber urine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inborn errors of bile acid synthesis can produ...</td>\n",
       "      <td>is autoimmune hepatitis a bile acid synthesis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The word convict here (elegcw /elegxo) means t...</td>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In-home tutors can earn anywhere from $10 to $...</td>\n",
       "      <td>how much does an average person make for tutoring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.   \\\n",
       "0  The approach is based on a theory of justice t...                                                                                                                                                                                                                                                                                       \n",
       "1  Colorâurine can be a variety of colors, most...                                                                                                                                                                                                                                                                                       \n",
       "2  Inborn errors of bile acid synthesis can produ...                                                                                                                                                                                                                                                                                       \n",
       "3  The word convict here (elegcw /elegxo) means t...                                                                                                                                                                                                                                                                                       \n",
       "4  In-home tutors can earn anywhere from $10 to $...                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "  )what was the immediate impact of the success of the manhattan project?  \n",
       "0  _________ justice is designed to repair the ha...                       \n",
       "1                          what color is amber urine                       \n",
       "2  is autoimmune hepatitis a bile acid synthesis ...                       \n",
       "3                                     elegxo meaning                       \n",
       "4  how much does an average person make for tutoring                       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:15:33.465972Z",
     "iopub.status.busy": "2024-11-19T19:15:33.465343Z",
     "iopub.status.idle": "2024-11-19T19:15:33.470203Z",
     "shell.execute_reply": "2024-11-19T19:15:33.469208Z",
     "shell.execute_reply.started": "2024-11-19T19:15:33.465941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset.columns = ['Text', 'Query']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:15:34.466128Z",
     "iopub.status.busy": "2024-11-19T19:15:34.465438Z",
     "iopub.status.idle": "2024-11-19T19:15:34.474081Z",
     "shell.execute_reply": "2024-11-19T19:15:34.473132Z",
     "shell.execute_reply.started": "2024-11-19T19:15:34.466094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The approach is based on a theory of justice t...</td>\n",
       "      <td>_________ justice is designed to repair the ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colorâurine can be a variety of colors, most...</td>\n",
       "      <td>what color is amber urine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inborn errors of bile acid synthesis can produ...</td>\n",
       "      <td>is autoimmune hepatitis a bile acid synthesis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The word convict here (elegcw /elegxo) means t...</td>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In-home tutors can earn anywhere from $10 to $...</td>\n",
       "      <td>how much does an average person make for tutoring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  The approach is based on a theory of justice t...   \n",
       "1  Colorâurine can be a variety of colors, most...   \n",
       "2  Inborn errors of bile acid synthesis can produ...   \n",
       "3  The word convict here (elegcw /elegxo) means t...   \n",
       "4  In-home tutors can earn anywhere from $10 to $...   \n",
       "\n",
       "                                               Query  \n",
       "0  _________ justice is designed to repair the ha...  \n",
       "1                          what color is amber urine  \n",
       "2  is autoimmune hepatitis a bile acid synthesis ...  \n",
       "3                                     elegxo meaning  \n",
       "4  how much does an average person make for tutoring  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:15:39.506049Z",
     "iopub.status.busy": "2024-11-19T19:15:39.505161Z",
     "iopub.status.idle": "2024-11-19T19:15:40.888109Z",
     "shell.execute_reply": "2024-11-19T19:15:40.887430Z",
     "shell.execute_reply.started": "2024-11-19T19:15:39.506012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:19:38.767670Z",
     "iopub.status.busy": "2024-11-19T19:19:38.766888Z",
     "iopub.status.idle": "2024-11-19T19:26:33.671956Z",
     "shell.execute_reply": "2024-11-19T19:26:33.671171Z",
     "shell.execute_reply.started": "2024-11-19T19:19:38.767634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "# Load and prepare the DataFrame\n",
    "df = pd.read_csv(\"doc_query_pairs.train.tsv\", sep='\\t')\n",
    "df.columns = ['Text', 'Query']  # Adjust this if your file has different column headers\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Function to preprocess the data\n",
    "\n",
    "def preprocess_function(examples):\n",
    "# Tokenize both the input texts and the queries in one call\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"Text\"],\n",
    "        text_target=examples[\"Query\"],\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\"  # Return as NumPy arrays if you're not immediately loading to a model, else use \"pt\" for PyTorch\n",
    "    )\n",
    "    \n",
    "    # Correct extraction of labels\n",
    "    # The tokenizer outputs are returned in a dictionary with input_ids, attention_mask, and labels (since text_target is used)\n",
    "    # The labels here are the input_ids for the target texts\n",
    "    model_inputs[\"labels\"] = model_inputs.pop('labels')\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.1) \n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'test': train_test_split['test']  \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535462a309f4a789d00f15c4280c37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/14 shards):   0%|          | 0/479475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ef0dbbc69f44f1a9efa2a8e1e005e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/53275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the dataset from disk\n",
    "dataset = load_from_disk(\"dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:29:31.105753Z",
     "iopub.status.busy": "2024-11-19T19:29:31.105055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:38:19.840493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-25 15:38:19.854646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732529299.872152 3308903 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732529299.877553 3308903 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 15:38:19.895528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhaskarc/miniconda3/envs/kalp_gpu/lib/python3.9/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments, BartTokenizer\n",
    "import torch\n",
    "\n",
    "# Specify a new cache directory with sufficient space\n",
    "saved_model_path = \"/data/bhaskarc/nirmal/IR/TinyBert/bart_base2/model/\"\n",
    "saved_tokenizer_path = \"/data/bhaskarc/nirmal/IR/TinyBert/bart_base2/tokenizer/\"\n",
    "\n",
    "# Load the model with a specified cache directory\n",
    "model = BartForConditionalGeneration.from_pretrained(saved_model_path)\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(saved_tokenizer_path)\n",
    "\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)  # Ensure the model is on the correct device\n",
    "print(f\"Model is using device: {device}\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=18000,  # Evaluation and saving happens every 500 steps\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,  # Only last 3 models are saved\n",
    "    num_train_epochs=2,\n",
    "    report_to=\"none\",  # Or 'wandb' for Weights & Biases \n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119868' max='119868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119868/119868 17:06:41, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.014976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.014512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.013844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.013619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.013351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.013087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=119868, training_loss=0.012282160976394764, metrics={'train_runtime': 61601.9595, 'train_samples_per_second': 15.567, 'train_steps_per_second': 1.946, 'total_flos': 5.847025084740403e+17, 'train_loss': 0.012282160976394764, 'epoch': 1.999983315119005})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart_base3/tokenizer/tokenizer_config.json',\n",
       " 'bart_base3/tokenizer/special_tokens_map.json',\n",
       " 'bart_base3/tokenizer/vocab.json',\n",
       " 'bart_base3/tokenizer/merges.txt',\n",
       " 'bart_base3/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model manually\n",
    "model.save_pretrained('bart_base3/model')\n",
    "tokenizer.save_pretrained('bart_base3/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T18:36:14.661814Z",
     "iopub.status.busy": "2024-11-19T18:36:14.661491Z",
     "iopub.status.idle": "2024-11-19T18:36:14.671921Z",
     "shell.execute_reply": "2024-11-19T18:36:14.671091Z",
     "shell.execute_reply.started": "2024-11-19T18:36:14.661789Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [0, 574, 29876, 8488, 7810, 4759, 22482, 4, 7810, 4759, 22482, 16, 10, 3286, 11, 10347, 1073, 4317, 18, 47898, 11170, 11, 20, 23026, 44936, 5855, 6, 8, 5, 317, 147, 37, 16, 6475, 7, 8386, 7736, 21194, 88, 1241, 10524, 29860, 994, 4, 404, 472, 386, 49, 3251, 259, 6, 19, 5, 9794, 16455, 840, 1069, 2987, 11, 7810, 4759, 22482, 4, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [0, 12196, 232, 16, 5, 7047, 39573, 2987, 11, 2569, 4759, 22482, 2034, 11, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Input IDs: [0, 6179, 24, 1364, 4, 287, 10, 1155, 3974, 41, 5102, 4454, 2280, 6, 63, 5770, 346, 16, 1166, 8, 11764, 7869, 136, 8503, 2189, 9, 1734, 9, 773, 4, 522, 1024, 64, 20359, 8, 912, 10, 1155, 6, 1649, 24, 13, 1283, 8, 6, 147, 2139, 6, 146, 7102, 4, 594, 19774, 8, 899, 7, 10696, 414, 4, 497, 1455, 198, 6791, 1096, 5102, 4454, 4387, 9852, 6, 6471, 227, 564, 8, 389, 153, 5102, 4454, 952, 7258, 4056, 7471, 4056, 711, 12745, 3695, 4056, 7471, 4056, 27, 2189, 7, 5, 496, 5102, 4454, 5423, 2521, 36, 487, 2606, 347, 43, 1230, 4, 5102, 4454, 414, 31, 349, 249, 1370, 16, 10696, 561, 19, 1122, 414, 31, 97, 1572, 13, 10, 675, 9, 80, 107, 4, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [0, 12196, 473, 41, 4862, 1649, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Input IDs: [0, 133, 381, 18048, 7184, 40, 213, 88, 1683, 11, 719, 193, 6, 61, 839, 122, 16, 5, 86, 13, 31568, 7, 120, 41, 381, 18048, 2472, 11, 317, 4, 4254, 66, 42, 2119, 569, 31, 5, 3263, 250, 35, 767, 7, 274, 6018, 3603, 6, 5, 381, 18048, 2178, 40, 5242, 35, 32600, 819, 8, 1521, 2820, 13, 722, 12, 1116, 12, 11131, 36, 725, 3196, 43, 5175, 19980, 2110, 36, 34816, 29, 43, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [0, 14746, 473, 47527, 213, 88, 1683, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Input IDs: [0, 133, 1609, 1471, 655, 30, 65, 165, 10, 1582, 2616, 177, 16, 3490, 332, 1008, 30, 5, 764, 2659, 2766, 268, 11, 1582, 2616, 26166, 6372, 4, 152, 177, 21, 702, 15, 644, 971, 6, 4525, 6, 23, 5, 5993, 1582, 417, 4399, 11, 188, 4942, 6, 5993, 4, 20, 507, 1471, 21, 764, 2659, 3490, 8, 4465, 158, 4, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [0, 21810, 2314, 5749, 426, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Input IDs: [0, 7605, 28274, 6, 5, 481, 45975, 4, 9257, 3166, 35976, 36, 5400, 779, 204, 6, 34094, 43, 16, 41, 470, 2384, 2701, 6, 275, 684, 13, 39, 173, 11, 5, 7571, 29, 6, 144, 10030, 11, 5, 774, 9, 2431, 7287, 6, 5, 6578, 9, 24237, 5503, 15, 20, 24237, 5893, 2907, 4, 112, 1437, 112, 8451, 301, 8, 756, 4, 1437, 132, 12845, 173, 4, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [0, 8155, 702, 4066, 1120, 15, 10512, 2553, 385, 7480, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Print some sample labels and inputs to check alignment\n",
    "for i in range(5):\n",
    "    print(\"Input IDs:\", encoded_dataset['train'][i]['input_ids'])\n",
    "    print(\"Labels:\", encoded_dataset['train'][i]['labels'])\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5839113,
     "sourceId": 9577761,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 200086959,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kalp_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
